{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shehzad-sudo/ML_HWork_52894_SE5/blob/main/NLP%20Project/BERT_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RDJJ9qagl6N"
      },
      "source": [
        "## importing the data and installing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mcdVUlETt8YA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57366a83-83f1-4ead-8daf-921d22f05e3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m498.0/498.0 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.3/462.3 KB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# !pip install tensorflow-hub\n",
        "# !pip install sentencepiece\n",
        "# !pip install tensorflow\n",
        "\n",
        "# !pip install seaborn\n",
        "\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kETUeFheuAiO",
        "outputId": "176ef74b-5285-4130-d9eb-34b985091366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.8.4\n",
            "Hub version:  0.12.0\n",
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "\n",
        "print(\"TF version: \", tf.__version__)\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ndpR5hAJuWOG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# For cleaning the text\n",
        "# import spacy\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import regex as re\n",
        "import string\n",
        "\n",
        "# For visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# For building our model\n",
        "import tensorflow.keras\n",
        "import sklearn\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nm8dQKtJgTdW"
      },
      "outputs": [],
      "source": [
        "# from transformers import DistilBertTokenizer\n",
        "# from transformers import TFDistilBertForSequenceClassification\n",
        "# from transformers import TextClassificationPipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget kaggle datasets download -d rmisra/news-category-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FteQ2Pu7p-0K",
        "outputId": "3f2c164c-9421-427a-f7b1-647ba7ef6fc2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEBUG output created by Wget 1.20.3 on linux-gnu.\n",
            "\n",
            "Reading HSTS entries from /root/.wget-hsts\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'index.html' (UTF-8) -> 'index.html' (UTF-8)\n",
            "--2023-01-30 14:47:17--  http://kaggle/\n",
            "Resolving kaggle (kaggle)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘kaggle’\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'index.html' (UTF-8) -> 'index.html' (UTF-8)\n",
            "--2023-01-30 14:47:17--  http://datasets/\n",
            "Resolving datasets (datasets)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘datasets’\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'index.html' (UTF-8) -> 'index.html' (UTF-8)\n",
            "--2023-01-30 14:47:17--  http://download/\n",
            "Resolving download (download)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‘download’\n",
            "URI encoding = ‘UTF-8’\n",
            "Converted file name 'news-category-dataset' (UTF-8) -> 'news-category-dataset' (UTF-8)\n",
            "--2023-01-30 14:47:17--  http://rmisra/news-category-dataset\n",
            "Resolving rmisra (rmisra)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘rmisra’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "qppZhky2tzzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KAGGLE_CONFIG_DIR\"] = '/content/gdrive/MyDrive/Kaggle'"
      ],
      "metadata": {
        "id": "pgjimEl-t916"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "_Si4muGmumNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rmisra/news-category-dataset"
      ],
      "metadata": {
        "id": "J-tngftiuvt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip news-category-dataset.zip -d news_data\n"
      ],
      "metadata": {
        "id": "vgmotTjXvuL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd news_data\n",
        "\n"
      ],
      "metadata": {
        "id": "UB_Cv2phwGvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "metadata": {
        "id": "hqv0UwwpwSB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfBUeWx2gUB4"
      },
      "source": [
        "## Importing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgRwyyO7vFbs"
      },
      "outputs": [],
      "source": [
        "### all the data you'll need\n",
        "\n",
        "_df = pd.read_json('News_Category_Dataset_v3.json', lines = True)\n",
        "df = _df.drop(_df.columns[[0,4,5]], axis = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt8k50x9gQYK"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYkdXLUOvZcj"
      },
      "outputs": [],
      "source": [
        "df['category'] = df['category'].astype('string')\n",
        "df['headline'] = df['headline'].astype('string')\n",
        "df['short_description'] = df['short_description'].astype('string')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d62pPW_TvvC7"
      },
      "outputs": [],
      "source": [
        "# df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg4X2TnNn7B3"
      },
      "outputs": [],
      "source": [
        "for index, row in df.iterrows():\n",
        "    i = df['category'].at[index]\n",
        "    \n",
        "    if(i == \"world news\"):\n",
        "        df['category'].at[index] = \"worldpost\" \n",
        "        \n",
        " \n",
        "    if( i==\"ARTS\"):\n",
        "        df['category'].at[index] = \"arts & culture\"\n",
        "        \n",
        "    if( i==\"wellness\"):\n",
        "        df['category'].at[index] = \"healthy living\"\n",
        "    \n",
        "    if( i==\"taste\"):\n",
        "        df['category'].at[index] = \"food & drink\"\n",
        "   \n",
        "    if( i==\"parenting\"):\n",
        "        df['category'].at[index] = \"parents\"\n",
        "   \n",
        "\n",
        "\n",
        "    \n",
        "# check that the species were converted correctly\n",
        "df['category'].unique()\n",
        "df['category'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DVMZ_cbn7B5"
      },
      "outputs": [],
      "source": [
        "df['headline'] = df['headline'].str.lower()\n",
        "df['category'] = df['category'].str.lower()\n",
        "df['short_description'] = df['short_description'].str.lower()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GICL9oQjpG8P"
      },
      "source": [
        "## Vizualizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSPcw-0zn7B6"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# # from nltk.tokenize import sent_tokenize\n",
        "# # print(stopwords.words('english'))\n",
        "\n",
        "def remove_stopword(text):\n",
        "    stop_word = set(stopwords.words('english'))\n",
        "#     words = word_tokenize(text)\n",
        "    return  \" \".join([x for x in text.split() if x not in stop_word])\n",
        "\n",
        "\n",
        "df['headline'] = df['headline'].apply(remove_stopword)\n",
        "df['short_description'] = df['short_description'].apply(remove_stopword)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWhXgCkin7B8"
      },
      "outputs": [],
      "source": [
        "def special_char(text):\n",
        "    reviews = ''\n",
        "    \n",
        "    for x in text:\n",
        "        if(x == \" \"):\n",
        "            reviews += \" \"\n",
        "            \n",
        "        elif(x.isalnum()):\n",
        "            reviews += x\n",
        "            \n",
        "    return reviews\n",
        "\n",
        "df['headline'] = df['headline'].apply(special_char)\n",
        "df['short_description'] = df['short_description'].apply(special_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSDkZtOmn7B9"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "\n",
        "# using headlines and short_description as input X\n",
        "\n",
        "df['text'] = df.headline + \" \" + df.short_description"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9R3bymHvvHt"
      },
      "outputs": [],
      "source": [
        "# top 30 locations in the dataset\n",
        "top_30 = df.groupby(['category']).count().text.sort_values(ascending = False)[:30]\n",
        "\n",
        "# plot the top 30\n",
        "\n",
        "plt.figure(figsize = (6,10))\n",
        "sns.barplot(x = top_30, y = top_30.index);\n",
        "plt.xlabel('number of news types');\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "import pandas as pd\n",
        "\n",
        "def make_resample(_df, column):\n",
        "\n",
        "    dfs_r = {}\n",
        "    dfs_c = {}\n",
        "    bigger = 1000\n",
        "    ignore = \"\"\n",
        "    for c in _df[column].unique():\n",
        "        dfs_c[c] = _df[df[column] == c]\n",
        "#         if dfs_c[c].shape[0] > bigger && bigger < 1000:\n",
        "#             bigger = dfs_c[c].shape[0]\n",
        "#             ignore = c\n",
        "\n",
        "    for c in dfs_c:\n",
        "#         if c == ignore:\n",
        "#             continue\n",
        "        dfs_r[c] = resample(dfs_c[c], \n",
        "                        replace=False,\n",
        "                        n_samples=100,\n",
        "                        random_state=1)\n",
        "    return pd.concat([dfs_r[c] for c in dfs_r] )"
      ],
      "metadata": {
        "id": "Hf7b1OnHJPie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_yfbuQKEn7CA"
      },
      "outputs": [],
      "source": [
        "df_balanced = make_resample(df,'category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH3kXEQOn7CA"
      },
      "outputs": [],
      "source": [
        "_df = df\n",
        "df = df_balanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkVIe1kfn7CA"
      },
      "outputs": [],
      "source": [
        "df = df.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VL--l_rn7CB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSoRPtyjn7CB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aKzlykBn7CB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "le = LabelEncoder()\n",
        "labelEncode = le.fit(df[\"category\"])\n",
        "print(labelEncode.classes_)         #prints labels by order as fitted in encoder\n",
        "label = labelEncode\n",
        "labelEncode = le.fit_transform(df[\"category\"])\n",
        "\n",
        "print(\"LabelEncode\")\n",
        "print(labelEncode)\n",
        "\n",
        "categorical_y = to_categorical(labelEncode)\n",
        "print(\"\\n To_Categorical one hot encode\")\n",
        "print(categorical_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1LN_OoEn7CC"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "x_train, x_test, y_train, y_test = train_test_split(df[['headline','short_description']], categorical_y, test_size = 0.1, random_state = 2, stratify = categorical_y)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rX9fSedPn7CC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dT8Zn3zbn7CD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Bs8ijwc0AVj"
      },
      "source": [
        "# **BERT!**\n",
        "Bidirectional Encoder Representations from Transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "Hn1LKa6en7CE"
      },
      "outputs": [],
      "source": [
        "# !pip install tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "vtMiwWTHn7CE"
      },
      "outputs": [],
      "source": [
        "# !pip install bert-tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "T-eiM0Lgvs1U"
      },
      "outputs": [],
      "source": [
        "# Bert Tokenizer for all of them\n",
        "\n",
        "# !wget https://raw.githubusercontent.com/tensorflow/models/master/official/nlp/bert/tokenization.py\n",
        "# from bert.tokenization import FullTokenizer\n",
        "# FullTokenizer = FullTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV64jxxkE_Sq",
        "scrolled": true,
        "outputId": "1b532e54-cda7-4426-dc31-3758e8456e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[101, 7592, 1010, 2129, 2024, 2017, 2651, 1029, 102, 2986, 4283, 102]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'[CLS] hello, how are you today? [SEP] fine thanks [SEP]'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize a sentence\n",
        "sentence = \"Hello, how are you today?\"\n",
        "sent2 = \"Fine thanks\"\n",
        "# tokens = tokenizer.encode_plus(['[CLS]'] + tokenizer.tokenize(sentence) + ['[SEP]'] + tokenizer.tokenize(sent2) + ['[SEP]']\n",
        "#                                ,return_attention_mask = True,    max_length = 66, truncation=True, \n",
        "# )\n",
        "\n",
        "tokens = tokenizer(sentence,sent2)\n",
        "\n",
        "\n",
        "decoded = tokenizer.decode(tokens[\"input_ids\"])\n",
        "print(tokens[\"input_ids\"])\n",
        "print(tokens[\"attention_mask\"])\n",
        "print(tokens[\"token_type_ids\"])\n",
        "decoded\n",
        "\n",
        "# Convert tokens to their corresponding IDs\n",
        "# token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "# token = tokenizer.encode(tokens)\n",
        "\n",
        "# segment_ids = tokenizer.create_token_type_ids_from_sequences(token)\n",
        "# attention_mask = tokenizer.create_mask(token)\n",
        "\n",
        "\n",
        "# print(attention_mask)\n",
        "# print(token_ids)\n",
        "# print(segment_ids)\n",
        "# print(token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6y3R7Snn7CG"
      },
      "outputs": [],
      "source": [
        "# ! pip install bert-tensorflow==1.0.1\n",
        "num_samples = df.shape[0]\n",
        "max_len = 200\n",
        "\n",
        "ids = np.zeros((num_samples, max_len))\n",
        "mask = np.zeros((num_samples, max_len))\n",
        "tok_type = np.zeros((num_samples,max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cE04Oqsin7CH"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text1,text2):\n",
        "    return tokenizer(text1,text2 ,padding = 'max_length',max_length = max_len)\n",
        "    \n",
        "\n",
        "encoded = df.apply(lambda x: tokenize_text(x.headline, x.short_description), axis=1)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "VRqx7Sa-n7CI"
      },
      "outputs": [],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkG6ajC2HjTU"
      },
      "outputs": [],
      "source": [
        "for i in range(num_samples):\n",
        "    ids[i] =  encoded[i]['input_ids']\n",
        "    mask[i] = encoded[i]['attention_mask']\n",
        "    tok_type[i] = encoded[i]['token_type_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asr0EH-Cn7CJ"
      },
      "source": [
        "### convert to tensor as the model is not fitting on ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqME9gJIn7CJ"
      },
      "outputs": [],
      "source": [
        "ids_ts = tf.convert_to_tensor(ids)\n",
        "mask_ts = tf.convert_to_tensor(mask)\n",
        "tok_type_ts = tf.convert_to_tensor(tok_type)\n",
        "\n",
        "\n",
        "\n",
        "ids_ts = tf.cast(ids_ts, tf.int32)\n",
        "mask_ts = tf.cast(mask_ts, tf.int32)\n",
        "tok_type_ts = tf.cast(tok_type_ts, tf.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9rSov8rin7CK",
        "outputId": "b94107fc-aef1-49a3-b98c-6d07daf767b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(41000, 200), dtype=int32, numpy=\n",
              "array([[  101, 23960,  5284, ...,     0,     0,     0],\n",
              "       [  101,  9130,  2936, ...,     0,     0,     0],\n",
              "       [  101,  2047,  2259, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,  7627,  2508, ...,     0,     0,     0],\n",
              "       [  101, 21372,  1047, ...,     0,     0,     0],\n",
              "       [  101, 10756,  5727, ...,     0,     0,     0]])>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvLOjjzhn7CK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "sWCjA2Sln7CK",
        "outputId": "4aa0b2aa-7ca4-4226-d1d0-a1fdba8b0883"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['arts & culture' 'black voices' 'business' 'college' 'comedy' 'crime'\n",
            " 'culture & arts' 'divorce' 'education' 'entertainment' 'environment'\n",
            " 'fifty' 'food & drink' 'good news' 'green' 'healthy living'\n",
            " 'home & living' 'impact' 'latino voices' 'media' 'money' 'parenting'\n",
            " 'parents' 'politics' 'queer voices' 'religion' 'science' 'sports' 'style'\n",
            " 'style & beauty' 'taste' 'tech' 'the worldpost' 'travel' 'u.s. news'\n",
            " 'weddings' 'weird news' 'wellness' 'women' 'world news' 'worldpost']\n",
            "LabelEncode\n",
            "[34 34 34 ...  7  7  7]\n",
            "\n",
            " To_Categorical one hot encode\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "le = LabelEncoder()\n",
        "labelEncode = le.fit(df[\"category\"])\n",
        "print(labelEncode.classes_)         #prints labels by order as fitted in encoder\n",
        "label = labelEncode\n",
        "labelEncode = le.fit_transform(df[\"category\"])\n",
        "\n",
        "print(\"LabelEncode\")\n",
        "print(labelEncode)\n",
        "\n",
        "categorical_y = to_categorical(labelEncode)\n",
        "print(\"\\n To_Categorical one hot encode\")\n",
        "print(categorical_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "EUqvJ3_Nn7CL"
      },
      "outputs": [],
      "source": [
        "# df1 = df[['a', 'b']]\n",
        "\n",
        "x = [ids,mask,tok_type]\n",
        "# x = tf.transpose(x)\n",
        "# x = encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "k2qheEWcn7CL"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "X1_train, X1_test, y_train, y_test = train_test_split(\n",
        "    ids, categorical_y, test_size = 0.1, random_state = 2, stratify = categorical_y)\n",
        "\n",
        "\n",
        "X2_train, X2_test, y_train, y_test = train_test_split( mask, categorical_y, test_size = 0.1, random_state = 2, stratify = categorical_y)\n",
        "\n",
        "X3_train, X3_test, y_train, y_test = train_test_split(\n",
        "        tok_type, categorical_y, test_size = 0.1, random_state = 2, stratify = categorical_y)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLn1nuawn7CM"
      },
      "outputs": [],
      "source": [
        "x_train = [X1_train,X2_train,X3_train]\n",
        "x_test = [X1_test,X2_test,X3_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkauwlU8n7CM"
      },
      "source": [
        "## Building a Bert Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7YijDeUn7CM"
      },
      "outputs": [],
      "source": [
        "preprocess ='https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\",trainable = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJqCE7LTn7CN"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TdSHvIkn7CN"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "# from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Bert_model():\n",
        "    \n",
        "    \n",
        "    preprocessor = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "\n",
        "    text_inputs = [tf.keras.layers.Input(shape=(), dtype=tf.string, name= 'text1'),\n",
        "                   tf.keras.layers.Input(shape=(), dtype=tf.string, name= 'text2')] # This SavedModel accepts up to 2 text inputs.\n",
        "\n",
        "\n",
        "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "    tokenized_inputs = [tokenize(segment) for segment in text_inputs]\n",
        "\n",
        "\n",
        "    seq_length = 94  # Your choice here.\n",
        "\n",
        "    bert_pack_inputs = hub.KerasLayer(\n",
        "        preprocessor.bert_pack_inputs,\n",
        "        arguments=dict(seq_length=seq_length))  # Optional argument.\n",
        "\n",
        "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    # text_inputs = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    # encoder_inputs = bert_preprocess(text_inputs)\n",
        "    text_out = bert_encoder(encoder_inputs)\n",
        "    \n",
        "    \n",
        "    x = tf.keras.layers.Dropout(0.0)(text_out['pooled_output'])\n",
        "    x = tf.keras.layers.Dense(80, activation='relu')(x)\n",
        "\n",
        "    out = tf.keras.layers.Dense(y_test.shape[1], activation='softmax', name='outputs')(x)\n",
        "\n",
        "    model = Model(inputs = text_inputs, outputs = out)\n",
        "\n",
        "    model.compile(tf.keras.optimizers.Adam(learning_rate=0.00009), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UN4S5A-n7CO"
      },
      "outputs": [],
      "source": [
        "bert_model = Bert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0jgtI74n7CO"
      },
      "outputs": [],
      "source": [
        "plot_model(bert_model,show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHwokxqZn7CP"
      },
      "outputs": [],
      "source": [
        "bert_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjpotsJ0n7CP"
      },
      "outputs": [],
      "source": [
        "# tf.config.optimizer.set_jit(False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train['headline'].to_numpy().astype('str')"
      ],
      "metadata": {
        "id": "hlLoiHcu2Wte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if(x_train['headline'].to_numpy().any()):\n",
        "#     print(x_train.headline)\n"
      ],
      "metadata": {
        "id": "D-gobp9D6b2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !nvidia-smi\n"
      ],
      "metadata": {
        "id": "a5R8AnS8DvhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from numba import cuda\n",
        "# device = cuda.get_current_device()\n",
        "# device.reset()\n",
        "\n"
      ],
      "metadata": {
        "id": "4JMNxL81EZD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IcmM1GFn7CP"
      },
      "outputs": [],
      "source": [
        "tf.config.run_functions_eagerly(True)\n",
        "\n",
        "\n",
        "bert_history = bert_model.fit([x_train['headline'].to_numpy().astype('str'),x_train['short_description'].to_numpy().astype('str')],\n",
        "                              y_train,\n",
        "                              epochs=2,\n",
        "                              batch_size=25,\n",
        "#                               validation_data=[x_test['headline'], x_test['short_description']]\n",
        "                              # validation_data=x_test['headline'].to_numpy().astype('str')\n",
        "\n",
        "                             )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cont_to_bin(_2darr):\n",
        "    #make an 2d array\n",
        "    final2d = np.empty(_2darr.shape,dtype = int)\n",
        "    \n",
        "    #iterate over each row\n",
        "    for i in range(0,_2darr.shape[0]):\n",
        "        #find greatest element\n",
        "        row = _2darr[i]\n",
        "        index = row.argmax()\n",
        "        \n",
        "        #make an array\n",
        "        temp = np.zeros( row.size )\n",
        "        temp[index] = 1\n",
        "        final2d[i] = temp\n",
        "        \n",
        "    return final2d"
      ],
      "metadata": {
        "id": "lQge_WwGqNkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test_ = bert_model.predict([x_test['headline'].to_numpy().astype('str'),x_test['short_description'].to_numpy().astype('str')])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nSadmMCotOu",
        "outputId": "f1dcd13b-2f47-40c7-f3d3-7517d67954b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train_ = bert_model.predict([x_train['headline'].to_numpy().astype('str'),x_train['short_description'].to_numpy().astype('str')])"
      ],
      "metadata": {
        "id": "hB0zEmocrWbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "\n",
        "y_pred_test = cont_to_bin(y_pred_test_)\n",
        "y_pred_train = cont_to_bin(y_pred_train_)\n",
        "\n",
        "\n",
        "score_f1_test = f1_score(y_test, y_pred_test,average = 'weighted')\n",
        "score_f1_train = f1_score(y_train, y_pred_train,average = 'weighted')\n",
        "\n",
        "score_f1_test_micro = f1_score(y_test, y_pred_test,average = 'micro')\n",
        "score_f1_train_micro = f1_score(y_train, y_pred_train,average = 'micro')\n",
        "\n",
        "\n",
        "print(\"Training Evaluation\")\n",
        "print(\"Weighted F1-Score: \", score_f1_train)\n",
        "print(\"Micro F1-Score: \", score_f1_train_micro)\n",
        "\n",
        "\n",
        "print('-' * 20)\n",
        "\n",
        "print(\"Weighted F1-Score: \", score_f1_test)\n",
        "print(\"Micro F1-Score: \", score_f1_test_micro)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4VabhMZot2n",
        "outputId": "19eb75df-53bd-482f-c955-22bb5d9ecca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Evaluation\n",
            "Weighted F1-Score:  0.9483761054181106\n",
            "Micro F1-Score:  0.9492378048780488\n",
            "--------------------\n",
            "Weighted F1-Score:  0.46368977133111594\n",
            "Micro F1-Score:  0.46798780487804875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyRbU3R-n7CQ"
      },
      "outputs": [],
      "source": [
        "# tfhub_handle_preprocess = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')\n",
        "def make_bert_preprocess_model(sentence_features, seq_length=128):\n",
        "#   \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "\n",
        "#   Args:\n",
        "#     sentence_features: a list with the names of string-valued features.\n",
        "#     seq_length: an integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "#   Returns:\n",
        "#     A Keras Model that can be called on a list or dict of string Tensors\n",
        "#     (with the order or names, resp., given by sentence_features) and\n",
        "#     returns a dict of tensors for input to BERT.\n",
        "#   \"\"\"\n",
        "\n",
        "  input_segments = [\n",
        "      tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "      for ft in sentence_features]\n",
        "\n",
        "  # Tokenize the text to word pieces.\n",
        "  bert_preprocess = hub.load(tfhub_handle_preprocess)\n",
        "  tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name='tokenizer')\n",
        "  segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "  # Optional: Trim segments in a smart way to fit seq_length.\n",
        "  # Simple cases (like this example) can skip this step and let\n",
        "  # the next step apply a default truncation to approximately equal lengths.\n",
        "#   truncated_segments = segments\n",
        "\n",
        "  # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "  # are model-dependent, so this gets loaded from the SavedModel.\n",
        "  packer = hub.KerasLayer(bert_preprocess.bert_pack_inputs,\n",
        "                          arguments=dict(seq_length=seq_length),\n",
        "                          name='packer')\n",
        "  model_inputs = packer(segments)\n",
        "  return tf.keras.Model(input_segments, model_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deEbP-sCn7CR",
        "outputId": "4bfd45eb-0604-48d9-c27c-63583d1f84f7"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"packer\" (type KerasLayer).\n\nin user code:\n\n    File \"C:\\Users\\Microsoft\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 222, in call  *\n        result = f()\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * [tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_2:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_1:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_3:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_5:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_4:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_6:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_8:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_7:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_9:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_11:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_10:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_12:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_14:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_13:0\", shape=(None,), dtype=int64))]\n        * 'bye you'\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64),\n     RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64),\n     RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"packer\" (type KerasLayer):\n  • inputs=['tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_3:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_4:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_5:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_6:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_7:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_8:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_9:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_10:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_11:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_12:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_13:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_14:0\", shape=(None,), dtype=int64))']\n  • training=None",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_text \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msome random test sentence\u001b[39m\u001b[38;5;124m'\u001b[39m]),\n\u001b[0;32m      2\u001b[0m              np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manother sentence\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmake_bert_preprocess_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhello\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbye you\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[30], line 34\u001b[0m, in \u001b[0;36mmake_bert_preprocess_model\u001b[1;34m(sentence_features, seq_length)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Optional: Trim segments in a smart way to fit seq_length.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Simple cases (like this example) can skip this step and let\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# the next step apply a default truncation to approximately equal lengths.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Pack inputs. The details (start/end token ids, dict of output tensors)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# are model-dependent, so this gets loaded from the SavedModel.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m packer \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mKerasLayer(bert_preprocess\u001b[38;5;241m.\u001b[39mbert_pack_inputs,\n\u001b[0;32m     32\u001b[0m                         arguments\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(seq_length\u001b[38;5;241m=\u001b[39mseq_length),\n\u001b[0;32m     33\u001b[0m                         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpacker\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mpacker\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel(input_segments, model_inputs)\n",
            "File \u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mC:\\Users\\MICROS~1\\AppData\\Local\\Temp\\__autograph_generated_filejy6sn3j2.py:75\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     73\u001b[0m     result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_cond)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope))), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     74\u001b[0m result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (result,)\n",
            "File \u001b[1;32mC:\\Users\\MICROS~1\\AppData\\Local\\Temp\\__autograph_generated_filejy6sn3j2.py:38\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mif_body_3\u001b[39m():\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m result, training\n\u001b[1;32m---> 38\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"packer\" (type KerasLayer).\n\nin user code:\n\n    File \"C:\\Users\\Microsoft\\anaconda3\\envs\\ML\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 222, in call  *\n        result = f()\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (2 total):\n        * [tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_2:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_1:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_3:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_5:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_4:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_6:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_8:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_7:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_9:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_11:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_10:0\", shape=(None,), dtype=int64)),\n     tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"inputs_12:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"inputs_14:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"inputs_13:0\", shape=(None,), dtype=int64))]\n        * 'bye you'\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64),\n     RaggedTensorSpec(TensorShape([None, None]), tf.int32, 1, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64),\n     RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (2 total):\n        * [RaggedTensorSpec(TensorShape([None, None, None]), tf.int32, 2, tf.int64)]\n        * TensorSpec(shape=(), dtype=tf.int32, name='seq_length')\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"packer\" (type KerasLayer):\n  • inputs=['tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_1:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_3:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_4:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_5:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_6:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_7:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_8:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_9:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_10:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_11:0\", shape=(None,), dtype=int64))', 'tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(\"Placeholder_12:0\", shape=(None,), dtype=int32), row_splits=Tensor(\"Placeholder_13:0\", shape=(None,), dtype=int64)), row_splits=Tensor(\"Placeholder_14:0\", shape=(None,), dtype=int64))']\n  • training=None"
          ]
        }
      ],
      "source": [
        "test_text = [np.array(['some random test sentence']),\n",
        "             np.array(['another sentence'])]\n",
        "\n",
        "make_bert_preprocess_model('hello','bye you')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzIW6e-yn7CR"
      },
      "outputs": [],
      "source": [
        "# text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(df['headline'])\n",
        "# outputs = bert_encoder(preprocessed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JeDIBNHn7CS"
      },
      "outputs": [],
      "source": [
        "import bert\n",
        "import tensorflow_hub as hub\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "# bert = TFAutoModel.from_pretrained('bert-base-cased' ,trainable = True )\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtjKaJGpn7CS"
      },
      "outputs": [],
      "source": [
        "bert_layer2 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/2\",\n",
        "                            trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPzcsga6n7CS"
      },
      "outputs": [],
      "source": [
        "bert_layer3 = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/2\",\n",
        "                            trainable=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE0RpT7Hn7CT"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "input_word_ids = Input(shape = (max_len, ), dtype = tf.int32, name = 'input_word_ids')\n",
        "input_mask = Input(shape = (max_len, ), dtype = tf.int32, name = 'input_mask')\n",
        "segment_ids = Input(shape = (max_len, ), dtype = tf.int32,   name = 'input_type_ids')\n",
        "\n",
        "input_bert = {\n",
        "    'input_mask': input_mask,\n",
        "     'input_type_ids': segment_ids,\n",
        "     'input_word_ids' : input_word_ids\n",
        "    \n",
        "}\n",
        "\n",
        "# pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "sequence_output = bert_layer(input_bert)\n",
        "\n",
        "# clf_output = sequence_output[:, 0, :]\n",
        "\n",
        "x = sequence_output['default']\n",
        "x = tf.keras.layers.Dense(60, activation='relu')(x)\n",
        "# x = tf.keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "out = tf.keras.layers.Dense(y_test.shape[1], activation='softmax', name='outputs')(x)\n",
        "\n",
        "model = Model(inputs = input_bert, outputs = out)\n",
        "# model = Model(inputs = [input_word_ids, input_mask, segment_ids], outputs = out)\n",
        "\n",
        "model.compile(tf.keras.optimizers.Adam(learning_rate=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soqCxx8qn7CU"
      },
      "outputs": [],
      "source": [
        "bert_model = model\n",
        "plot_model(bert_model,show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c3b93jSn7CV",
        "outputId": "103d069c-41fa-4bb6-f71f-ac0d7af7ba87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "123/123 [==============================] - 65s 532ms/step - loss: 3.7470 - accuracy: 0.0203 - val_loss: 3.7281 - val_accuracy: 0.0244\n",
            "Epoch 2/40\n",
            "123/123 [==============================] - 80s 654ms/step - loss: 3.7418 - accuracy: 0.0182 - val_loss: 3.7356 - val_accuracy: 0.0244\n",
            "Epoch 3/40\n",
            "123/123 [==============================] - 109s 886ms/step - loss: 3.7459 - accuracy: 0.0233 - val_loss: 3.7416 - val_accuracy: 0.0244\n",
            "Epoch 4/40\n",
            "123/123 [==============================] - 103s 835ms/step - loss: 3.7457 - accuracy: 0.0184 - val_loss: 3.7356 - val_accuracy: 0.0244\n",
            "Epoch 5/40\n",
            "123/123 [==============================] - 102s 829ms/step - loss: 3.7460 - accuracy: 0.0198 - val_loss: 3.7395 - val_accuracy: 0.0244\n",
            "Epoch 6/40\n",
            "123/123 [==============================] - 99s 802ms/step - loss: 3.7429 - accuracy: 0.0203 - val_loss: 3.7335 - val_accuracy: 0.0244\n",
            "Epoch 7/40\n",
            " 43/123 [=========>....................] - ETA: 1:03 - loss: 3.7466 - accuracy: 0.0202"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [177]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bert_history \u001b[38;5;241m=\u001b[39m \u001b[43mbert_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                              \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                             \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "bert_history = bert_model.fit([x_train[1],x_train[2],x_train[0]],\n",
        "                              y_train,\n",
        "                              epochs=40,\n",
        "                              batch_size=30,\n",
        "                              validation_data=[[x_test[1],x_test[2],x_test[0]],y_test]\n",
        "                             )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VZPz32Qn7CW",
        "outputId": "adcfc637-be0b-4ea3-a4cd-fa1fa9a44278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "129/129 [==============================] - 37s 288ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred_test = bert_model.predict(x = [x_test[1],x_test[2],x_test[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYZLoM6pn7CW",
        "outputId": "4a67766a-ff08-4092-dd88-6a1577c1b4eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593],\n",
              "       [0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593],\n",
              "       [0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593],\n",
              "       ...,\n",
              "       [0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593],\n",
              "       [0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593],\n",
              "       [0.02763289, 0.02314796, 0.02345162, ..., 0.02345989, 0.0251071 ,\n",
              "        0.02241593]], dtype=float32)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxaqWFXnn7CX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq2UTozDn7CX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlp9K-0wn7CX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIFwS0Wzn7CY"
      },
      "outputs": [],
      "source": [
        "def build_model(bert_layer, max_len=512):\n",
        "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
        "    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    \n",
        "    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "    \n",
        "    clf_output = sequence_output[:, 0, :]\n",
        "    \n",
        "    lay = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    lay = tf.keras.layers.Dense(32, activation='relu')(lay)\n",
        "    lay = tf.keras.layers.Dropout(0.2)(lay)\n",
        "    out = tf.keras.layers.Dense(5, activation='softmax')(lay)\n",
        "    \n",
        "    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n",
        "    model.compile(tf.keras.optimizers.Adam(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCKEoDp6n7CY",
        "outputId": "8284af4f-d507-4ea9-d1a6-4efbd87479ef"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'bert_layer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model(\u001b[43mbert_layer\u001b[49m, max_len\u001b[38;5;241m=\u001b[39mx_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'bert_layer' is not defined"
          ]
        }
      ],
      "source": [
        "model = build_model(bert_layer, max_len=x_train.shape[0])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8qJfnqvn7CZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBwXpjQTn7CZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOiG-9Zen7CZ"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ke8YLV3n7CZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_a9cBWDon7Ca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg9LogC8n7Ca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zELc0tbln7Ca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHD_H-mbn7Ca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SarvZsl_n7Cb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-QiVE_71jhl"
      },
      "source": [
        "## **The BERT Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-9ErgKL1ilQ",
        "outputId": "7cf5e863-433c-46ba-cdc7-81d1d3831529"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "<>:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.optimizer is 'SGD':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif self.optimizer is 'Adam':\n"
          ]
        }
      ],
      "source": [
        "class TextClassifier:\n",
        "    \n",
        "    def __init__(self, tokenizer, bert_layer, max_len, lr = 0.0001,\n",
        "                 epochs = 15, batch_size = 32,\n",
        "                 activation = 'relu', optimizer = 'Adam',\n",
        "                 beta_1=0.9, beta_2=0.999, epsilon=1e-07,\n",
        "                 metrics = ['accuracy','recall','precision'], loss = 'categorical_crossentropy'):\n",
        "        \n",
        "        self.lr = lr\n",
        "        self.epochs = epochs\n",
        "        self.max_len = max_len\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "        self.bert_layer = bert_layer\n",
        "        \n",
        "\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "        self.beta_1 = beta_1\n",
        "        self.beta_2 = beta_2\n",
        "        self.epsilon =epsilon\n",
        "        \n",
        "        self.metrics = metrics\n",
        "        self.loss = loss\n",
        "\n",
        "        \n",
        "    def encode(self, texts):\n",
        "        \n",
        "        all_tokens = []\n",
        "        masks = []\n",
        "        segments = []\n",
        "        \n",
        "        for text in texts:\n",
        "            \n",
        "            tokenized = self.tokenizer.convert_tokens_to_ids(['[CLS]'] + self.tokenizer.tokenize(text) + ['[SEP]'])\n",
        "            \n",
        "            len_zeros = self.max_len - len(tokenized)\n",
        "            \n",
        "            \n",
        "            padded = tokenized + [0] * len_zeros\n",
        "            mask = [1] * len(tokenized) + [0] * len_zeros\n",
        "            segment = [0] * self.max_len\n",
        "            \n",
        "            all_tokens.append(padded)\n",
        "            masks.append(mask)\n",
        "            segments.append(segment)\n",
        "        \n",
        "        return np.array(all_tokens), np.array(masks), np.array(segments)\n",
        "\n",
        "\n",
        "    def make_model(self):\n",
        "        \n",
        "        # Shaping the inputs to our model\n",
        "        \n",
        "        input_ids = Input(shape = (self.max_len, ), dtype = tf.int32, name = 'input_ids')\n",
        "        \n",
        "        input_mask = Input(shape = (self.max_len, ), dtype = tf.int32, name = 'input_mask')\n",
        "        \n",
        "        segment_ids = Input(shape = (self.max_len, ), dtype = tf.int32,  name = 'segment_ids')\n",
        "\n",
        "        \n",
        "        pooled_output, sequence_output = bert_layer2([input_ids, input_mask, segment_ids] )\n",
        "\n",
        "\n",
        "\n",
        "        clf_output = sequence_output[:, 0, :]\n",
        "        \n",
        "        \n",
        "        out = tf.keras.layers.Dense(30, activation = self.activation)(clf_output)\n",
        "\n",
        "        out = tf.keras.layers.Dense(1, activation = self.activation)(clf_output)\n",
        "        \n",
        "        \n",
        "        model = Model(inputs = [input_ids, input_mask, segment_ids], outputs = out)\n",
        "        \n",
        "        # define the optimizer\n",
        "\n",
        "        if self.optimizer is 'SGD':\n",
        "            optimizer = SGD(learning_rate = self.lr)\n",
        "\n",
        "        elif self.optimizer is 'Adam': \n",
        "            optimizer = Adam(learning_rate = self.lr, beta_1=self.beta_1, beta_2=self.beta_2, epsilon=self.epsilon)\n",
        "\n",
        "        model.compile(loss = self.loss, optimizer = self.optimizer, metrics = [self.metrics])\n",
        "        \n",
        "        print('Model is compiled with {} optimizer'.format(self.optimizer))\n",
        "        \n",
        "        return model\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    def train(self, x):    \n",
        "        \n",
        "        checkpoint = ModelCheckpoint('model.h5', monitor='val_loss',\n",
        "                                     save_best_only=True)\n",
        "            \n",
        "        \n",
        "        model = self.make_model()\n",
        "        \n",
        "        X = self.encode(x['cleaned_text'])\n",
        "        Y = x['target']\n",
        "        \n",
        "        model.fit(X, Y, shuffle = True, validation_split = 0.2, \n",
        "                  batch_size=self.batch_size, epochs = self.epochs,\n",
        "                  callbacks=[checkpoint])\n",
        "                \n",
        "        print('Model is fit!')\n",
        "        \n",
        "            \n",
        "    def predict(self, x):\n",
        "        \n",
        "        X_test_encoded = self.encode(x['cleaned_text'])\n",
        "        best_model = tf.keras.models.load_model('model.h5',custom_objects={'KerasLayer':hub.KerasLayer})\n",
        "        y_pred = best_model.predict(X_test_encoded)\n",
        "        \n",
        "        \n",
        "        return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7jyLXYU19bo"
      },
      "outputs": [],
      "source": [
        "classifier = TextClassifier(tokenizer = tokenizer, bert_layer = bert_layer2,\n",
        "                              max_len = max_len, lr = 0.001,\n",
        "                              epochs = 7,  activation = 'relu',\n",
        "                              batch_size = 32,optimizer = 'SGD',\n",
        "                              beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "1xrLecbU1pjC",
        "outputId": "c878a4b5-d02f-4dcd-cc24-1c471d14b8a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.optimizer is 'SGD':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif self.optimizer is 'Adam':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.optimizer is 'SGD':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif self.optimizer is 'Adam':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.optimizer is 'SGD':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif self.optimizer is 'Adam':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:79: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if self.optimizer is 'SGD':\n",
            "C:\\Users\\ALI\\AppData\\Local\\Temp\\ipykernel_22916\\2247014216.py:82: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  elif self.optimizer is 'Adam':\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"keras_layer\" (type KerasLayer).\n\nin user code:\n\n    File \"C:\\Users\\ALI\\anaconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 350) dtype=int32>,\n     <tf.Tensor 'inputs_1:0' shape=(None, 350) dtype=int32>,\n     <tf.Tensor 'inputs_2:0' shape=(None, 350) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer\" (type KerasLayer):\n  • inputs=['tf.Tensor(shape=(None, 350), dtype=int32)', 'tf.Tensor(shape=(None, 350), dtype=int32)', 'tf.Tensor(shape=(None, 350), dtype=int32)']\n  • training=False",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [111]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheadline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcategorical_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36mTextClassifier.train\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):    \n\u001b[0;32m     96\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.h5\u001b[39m\u001b[38;5;124m'\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     97\u001b[0m                                  save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 100\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    103\u001b[0m     Y \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36mTextClassifier.make_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m input_mask \u001b[38;5;241m=\u001b[39m Input(shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len, ), dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint32, name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_mask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     60\u001b[0m segment_ids \u001b[38;5;241m=\u001b[39m Input(shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len, ), dtype \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mint32,  name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegment_ids\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m pooled_output, sequence_output \u001b[38;5;241m=\u001b[39m \u001b[43mbert_layer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_ids\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m clf_output \u001b[38;5;241m=\u001b[39m sequence_output[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[0;32m     70\u001b[0m out \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m30\u001b[39m, activation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation)(clf_output)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6ze9t59t.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m     72\u001b[0m     result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_cond)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope))), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     73\u001b[0m result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 74\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mnot_(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_6\u001b[39m():\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (result,)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6ze9t59t.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmart_cond\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograph_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file6ze9t59t.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     70\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     71\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 72\u001b[0m result \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(smart_cond)\u001b[38;5;241m.\u001b[39msmart_cond, (ag__\u001b[38;5;241m.\u001b[39mld(training), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), fscope)), ag__\u001b[38;5;241m.\u001b[39mautograph_artifact(\u001b[38;5;28;01mlambda\u001b[39;00m : ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(f), (), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), fscope))), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
            "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer\" (type KerasLayer).\n\nin user code:\n\n    File \"C:\\Users\\ALI\\anaconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 350) dtype=int32>,\n     <tf.Tensor 'inputs_1:0' shape=(None, 350) dtype=int32>,\n     <tf.Tensor 'inputs_2:0' shape=(None, 350) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer\" (type KerasLayer):\n  • inputs=['tf.Tensor(shape=(None, 350), dtype=int32)', 'tf.Tensor(shape=(None, 350), dtype=int32)', 'tf.Tensor(shape=(None, 350), dtype=int32)']\n  • training=False"
          ]
        }
      ],
      "source": [
        "classifier.train([df['headline'],categorical_y])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eSWkfWt52ABp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip2km7Q7XTcg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ_x1DHqVOK0"
      },
      "outputs": [],
      "source": [
        "# Optional\n",
        "# Explore BERT's dictionary file\n",
        "with open(vocabulary_file) as f:\n",
        "    dic = f.readlines()\n",
        "pd.Series(dic)[pd.Series(dic).str.contains('cru')]\n",
        "#custom_objects={'KerasLayer':hub.KerasLayer}\n",
        "\n",
        "# Testing your predictions:\n",
        "\n",
        "perfect_submission = pd.read_csv('Kaggle_NLP_competition/perfect_submission.csv')\n",
        "\n",
        "y_pred = np.round(classifier.predict(test_cleaned))\n",
        "print('The score of prediction: ', sklearn.metrics.f1_score(perfection.target, y_pred, average = 'micro'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}